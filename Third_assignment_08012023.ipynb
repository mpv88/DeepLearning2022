{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mpv88/DeepLearning2022/blob/main/Third_assignment_08012023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xoo9zfb99yQb"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/lorenzobasile/DeepLearning2022/blob/main/7_forward_forward.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28U3i-Zo3Y75"
      },
      "source": [
        "# Third assignment - 01/2023 - mattia pividori (s284690)\n",
        "\n",
        "\n",
        "1.   Read Hinton's [paper](https://www.cs.toronto.edu/~hinton/FFA13.pdf) about the Forward Forward algorithm.\n",
        "2.   Reproduce the experiment described at page 5 of the paper.\n",
        "3.   Experiment with two of the following three points for future work reported in the paper and discuss your findings:\n",
        "    * A) What is the best activation function to use? \n",
        "    * B) What is the best goodness function to use?\n",
        "    * C) Can positive and negative passes be widely separated in time as they would be if the negative passes were done during sleep?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0Jo434asKrS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6acd07b7-1253-4cdb-a5eb-bf643bf3c385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/DeepLearning2022\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive/DeepLearning2022"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfbM76wz9_kg"
      },
      "source": [
        "# The Forward Forward algorithm\n",
        "\n",
        "The [Forward Forward algorithm](https://www.cs.toronto.edu/~hinton/FFA13.pdf) has been presented by Geoffrey Hinton (one of the \"Deep Learning godfathers\") at NeurIPS 2022, less than a month ago.\n",
        "\n",
        "It is a novel technique for Neural Network optimization, alternative to standard Backpropagation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztmvsf2WB94X"
      },
      "source": [
        "Over the last decades, backprop has been so successful that neuroscientists have been looking for proofs that the brain actually learns in a similar way. However, that does not seem to happen. Moreover, backprop encounters serious limitations if the model is not exactly defined in mathematical terms: if the forward pass is a black box, there is no possibility to make a backward pass (as we don't know what to differentiate).\n",
        "\n",
        "Even if (for the moment) it was not presented with the goal of substituting backprop for practical applications, the Forward Forward algorithm aims at solving some of these problems, using a layer-by-layer learning approach that does not require backward propagation of gradients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-42jTD10GapS"
      },
      "source": [
        "## MNIST classification through FF\n",
        "\n",
        "Let's see how FF works through a practical example on MNIST classification.\n",
        "\n",
        "Citing the paper,  \"the idea is to replace the forward and backward passes of backpropagation by two forward\n",
        "passes that operate in exactly the same way as each other, but on different data and with opposite\n",
        "objectives. The positive pass operates on real data and adjusts the weights to increase the goodness in\n",
        "every hidden layer. The negative pass operates on \"negative data\" and adjusts the weights to decrease\n",
        "the goodness in every hidden layer. This paper explores two different measures of goodness – the\n",
        "sum of the squared neural activities and the negative sum of the squared activities, but many other\n",
        "measures are possible.\"\n",
        "\n",
        "Thus, we have to find a way to define \"positive\" and \"negative\" data. If we want to classify MNIST, a data point being positive means that it somehow contains the right assignment of an image to its corresponding class. Hence, we can define a positive datapoint by embedding the right classification into the image and a negative datapoint by embedding a random classification. To do so, we can exploit the fact that there is a black frame around the digit, and we can use the top 10 pixels on the left to embed class information.\n",
        "\n",
        "![](https://github.com/lorenzobasile/DeepLearning2022/blob/main/images/ff_mnist.png?raw=1)\n",
        "\n",
        "Then, the layers of the network are trained one at a time with the objective of assigning high activation values (high goodness) to positive points and low to negative ones. However, if there are many layers, it would be trivial for following layers to rely on the information coming from the previous ones (if the activations of layer $i$ are high, this drastically increases the probability that the activations of layer $i+1$ are high as well). To avoid this phenomenon and make layers learn different features, it is necessary to normalize the activation vector to have norm $1$.\n",
        "\n",
        "At the end, at evaluation time, one can query the network with a certain image with all possible labels, and take the argmax of the goodnesses to obtain the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zeyKi7Sj1gcn"
      },
      "outputs": [],
      "source": [
        "class Net(torch.nn.Module):\n",
        "  def __init__(self, dimensions):\n",
        "    super().__init__()\n",
        "    self.layers = torch.nn.ModuleList([ReLULayer(dimensions[i], dimensions[i+1]) for i in range(len(dimensions)-1)])\n",
        "  \n",
        "  def predict(self, x):\n",
        "    goodness_per_label = []\n",
        "    for label in range(10):\n",
        "      x_lab = label_images(x, label)\n",
        "      goodness = []\n",
        "      for i, layer in enumerate(self.layers):\n",
        "        x_lab = layer(x_lab)\n",
        "        if i > 0:\n",
        "          goodness.append(pow(x_lab, 2).mean(dim=1, keepdim=False)) # Σ[relu(h)^2] .sum(dim=1, keepdim=False)\n",
        "      goodness_per_label.append(sum(goodness).unsqueeze(1))\n",
        "    goodness_per_label = torch.cat(goodness_per_label, 1)\n",
        "    return torch.argmax(goodness_per_label, dim=1) # set to argmin for point 3.B\n",
        "    \n",
        "  def train(self, x_pos, x_neg):\n",
        "    for layer in self.layers:\n",
        "      x_pos, x_neg = layer.train(x_pos, x_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zhuC5SwH1iCz"
      },
      "outputs": [],
      "source": [
        "def normalize(x):\n",
        "  return torch.nn.functional.normalize(x, p=2.0, dim=1, eps=1e-12) #x/x.norm(p=2, dim=1, keepdim=True, dtype=torch.float) activation normalized by L2-norm to get direction only\n",
        "\n",
        "class ReLULayer(torch.nn.Module):\n",
        "  def __init__(self, in_features, out_features):\n",
        "    super().__init__()\n",
        "    self.linear = torch.nn.Linear(in_features, out_features)\n",
        "    self.relu = torch.nn.ReLU() # ['torch.nn.ReLU()', 'torch.nn.LeakyReLU(0.25)', 'torch.nn.ELU(alpha=1.0)', 'torch.nn.CELU(alpha=1.0)', 'torch.nn.SELU()', 'torch.nn.GELU(approximate='none')', 'torch.nn.Threshold(threshold=0, value=-.5)', 'torch.nn.Sigmoid()', 'torch.nn.Tanh()', 'torch.nn.Softmax(dim=1)']\n",
        "    self.optimizer = torch.optim.Adam(self.parameters(), lr=0.03)\n",
        "    self.threshold = 2 # set to 0.5 for point 3.A\n",
        "    self.num_epochs = 1000 # set to 2000 for point 3.C\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x_direction = normalize(x)\n",
        "    return self.relu(self.linear(x_direction))\n",
        "\n",
        "  def train(self, x_pos, x_neg):\n",
        "    for i in range(self.num_epochs):\n",
        "      #positive_goodness = torch.zeros(x_pos.size(dim=0)).to(device) # uncomment for point 3.C\n",
        "      #negative_goodness = torch.zeros(x_neg.size(dim=0)).to(device) # uncomment for point 3.C\n",
        "      positive_goodness = self.forward(x_pos).pow(2).mean(dim=1, keepdim=False) # positive goodness step .sum(dim=1, keepdim=False)\n",
        "      negative_goodness = self.forward(x_neg).pow(2).mean(dim=1, keepdim=False) # negative goodness step .sum(dim=1, keepdim=False)\n",
        "      l = torch.log(1 + torch.exp(torch.cat([-positive_goodness + self.threshold, # maximize positive goodness and viceversa\n",
        "                                             +negative_goodness - self.threshold]))).mean() # minimize negative goodness and viceversa\n",
        "      self.optimizer.zero_grad()\n",
        "      l.backward(retain_graph=False)\n",
        "      self.optimizer.step()\n",
        "    return self.forward(x_pos).detach(), self.forward(x_neg).detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "a1dSgF_m1jW6",
        "outputId": "3e532b60-4563-4f13-d9ac-f5ca507209dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.9306833148002625\n",
            "Test accuracy: 0.9297999739646912\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# instantiate neural net and fix seed\n",
        "net = Net([784, 500, 500]).to(device)\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# import normalized dataset to dataloaders\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.1307,), (0.3081,)), torchvision.transforms.Lambda(torch.flatten)])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST('./data/', transform=transform,  train=True, download=True)\n",
        "testset = torchvision.datasets.MNIST('./data/', transform=transform, train=False, download=True)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=60000, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10000, shuffle=False)\n",
        "\n",
        "def label_images(images, labels):\n",
        "  '''input are: (batch_size, 28x28) images and (batch_size, 1) labels \n",
        "     output is: (batch_size, 28x28) label-embedded images'''\n",
        "  embedded_images = images.detach().clone() # in our case (60000x784)\n",
        "  embedded_images[[ _ for _ in range(embedded_images.size(dim=0))], labels] = images.max(dim=1)[0]\n",
        "  plt.imshow(embedded_images[1234].cpu().reshape(28,28), cmap='gray') # print sample embedded image\n",
        "  return embedded_images\n",
        "\n",
        "# unpack train set and create positive/negative samples \n",
        "x, y = next(iter(trainloader))\n",
        "x = x.to(device)\n",
        "y = y.to(device)\n",
        "\n",
        "x_pos = label_images(x, y)\n",
        "rnd = torch.randperm(x.size(0))\n",
        "x_neg = label_images(x, y[rnd])\n",
        "\n",
        "# launch training\n",
        "net.train(x_pos, x_neg)\n",
        "print('Train accuracy:', net.predict(x).eq(y).float().mean().item())\n",
        "\n",
        "# unpack test set\n",
        "x_test, y_test = next(iter(testloader))\n",
        "x_test = x_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "# launch trained model on test set\n",
        "print('Test accuracy:', net.predict(x_test).eq(y_test).float().mean().item())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The experiment outlined at page 5 of Hinton's paper, here approximated with Pytorch, leads to the following results: <br/>\n",
        "Train accuracy: 0.933 and Test accuracy: 0.934 <br/>\n",
        "with the small modification of using the mean of squared activations instead of their sum (outlined in paper)."
      ],
      "metadata": {
        "id": "QbvuyJLTyW7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To address the point 3.A we search if, ceteris paribus (so keeping constant all the other elements of our FF architecture), there is a specific activation function which is markedly better than the others (among the most common ones), namely:\n",
        "\n",
        "* ReLU (nn.ReLU): train accuracy = 0.933, test accuracy = 0.934 [Baseline case]\n",
        "* Leaky ReLU (nn.LeakyReLU(slope)), for different levels of slope parameter: \n",
        "      * slope=0.25, train accuracy = 0.902, test accuracy = 0.904\n",
        "      * slope=0.50, train accuracy = 0.825, test accuracy = 0.823\n",
        "      * slope=0.75, train accuracy = 0.743, test accuracy = 0.742\n",
        "\n",
        "* Exponential Linear Unit (nn.ELU): train accuracy = 0.938, test accuracy = 0.937\n",
        "* Continuously Differentiable Exponential Linear Unit (nn.CELU): train accuracy = 0.938, test accuracy = 0.937\n",
        "* Scaled Exponential Linear Unit (nn.SELU): train accuracy = 0.911, test accuracy = 0.912\n",
        "* Gaussian Error Linear Units (nn.GELU): train accuracy = 0.946, test accuracy = 0.943\n",
        "* Threshold (nn.nn.Threshold): train accuracy = 0.944, test accuracy = 0.943  \n",
        "<br/> (for the last three activation functions tested, we lowered the threshold from the default value of 2 to 0.5, so to allow the learning even for functions whose natural upper bound value is capped at 1)  <br/>\n",
        "* Sigmoid (nn.Sigmoid): train accuracy = 0.173, test accuracy = 0.171\n",
        "* Tanh (nn.Tanh): train accuracy = 0.265, test accuracy = 0.256\n",
        "* Softmax (nn.Softmax(dim=1)): train accuracy = 0.099, test accuracy = 0.098\n",
        "\n",
        "Among the activation functions tested, the GELU seems to lead to the best results.\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        " \n"
      ],
      "metadata": {
        "id": "4AuVAhitytX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the second point (3.B), we would like to see if there is a goodness function to use which may be considered better than the others. Starting from what proposed in Hinton's paper at page 2 (see also Footnote 4), the base formulation examined is that of \"[...] the sum of the squares of the activities\n",
        "of the rectified linear neurons in that layer [...]\", where as already mentioned, we replace the sum with the mean. Alternatively we may use the negative sum (mean) of the squared activities (which implies for the loss function to minimize the sum (or mean) squared activities for positive data and maximize it for negative data), or the unsquared activities (see page 15, Footnote 21) in both versions. <br/>\n",
        "\n",
        "RESULTS: <br/>\n",
        "The result using the negative mean of squared activities (thus looking for argmin) is slighly worse than the base case of point 2:<br/>\n",
        "Train accuracy: 0.8965666890144348 and Test accuracy: 0.8944999575614929 <br/>\n",
        "\n",
        "The result when minimizing the sum of unsquared activities for positive data (thus layer normalization must normalize the sum of the activities, not the sum of their squares) while maximizing the sum of unsquared activites for negative data is: <br/>\n",
        "Train accuracy: 0.784416675567627 and Test accuracy: 0.779699981212616 <br/>\n",
        "\n",
        "The result for maximizing the sum of unsquared activities for positive data and minimizing the sum of unsquared activites for negative data finally is: <br/>\n",
        "Train accuracy: 0.4275333285331726 and Test accuracy: 0.43039998412132263\n",
        "\n",
        "All the above results are obtained keeping a threshold level fixed to 2.\n"
      ],
      "metadata": {
        "id": "YIyIkzwH-8qH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The third point (3.C) worth examining is if instead of executing at the same time both the positive and the negative passes, it would be equivalent (or at least not much worse) -in terms of overall accuracy- a wider separation in time between the two types of passes, ceteris paribus. This kind of alteration of the baseline running sequence -Hinton suggests- is intended to mimic more closely the sleep-wake cycle we observe into typical biological functioning, where the sleep phase would correspond to the 'negative' steps, while the wake phase to 'positive' ones.\n",
        "We tried three alternatives in this regard, with increasing separation between the 2 states during the training relative to the one of the base case previously computed. Note that the overall n° of epochs has been doubled from 1000 to 2000 to cope with the alternative calculation of goodness measures.\n",
        "1. 'small separation', alternating positive steps on even (odd) epochs and negative steps on odd (even) epochs, so to have a single epoch separation;\n",
        "```\n",
        "      if i==0 or (i%2)!=0:\n",
        "        positive_goodness = self.forward(x_pos).pow(2).mean(dim=1, keepdim=False)\n",
        "      else:\n",
        "        negative_goodness = self.forward(x_neg).pow(2).mean(dim=1, keepdim=False)\n",
        "```\n",
        "2. 'medium separation', alternating positive and negative steps with frequency equal to 1/4 of the total number of epochs (i.e. about 500 epochs);\n",
        "```\n",
        "      if i<500 or (i>999 and i<1500):\n",
        "        positive_goodness = self.forward(x_pos).pow(2).mean(dim=1, keepdim=False)\n",
        "      else:\n",
        "        negative_goodness = self.forward(x_neg).pow(2).mean(dim=1, keepdim=False)\n",
        "```\n",
        "3. 'large separation', alternating positive and negative steps with frequency equal to 1/2 of the total number of epochs (i.e. about 1000 epochs);\n",
        "```\n",
        "      if i<1000:\n",
        "        positive_goodness = self.forward(x_pos).pow(2).mean(dim=1, keepdim=False)\n",
        "      else:\n",
        "        negative_goodness = self.forward(x_neg).pow(2).mean(dim=1, keepdim=False)\n",
        "```\n",
        "\n",
        "Our expectations, following the preliminary results showed in Fig. 5 of Hinton's paper, are that accuracy should be inversely related to the 2-passes separation (i.e. in the limit case of sleep deprivation, equal to the absence of negative steps in the model, the (biological) system is expected to fall apart).\n",
        "\n",
        "RESULTS: <br/>\n",
        "1. 'Small separation' with positive steps on even epochs and negative on odd ones are:<br/>\n",
        "Train accuracy: 0.874 and Test accuracy: 0.882; <br/>\n",
        "Note that if we start with a negative step instead, then results drop to 0.099 accuracy in training and 0.098 in testing.\n",
        "2. 'Medium separation', with positive and negative steps with frequency 500 epochs: <br/> Train accuracy: 0.099 Test accuracy: 0.099.\n",
        "3. 'Large separation', with positive and negative steps with frequency 1000 epochs: <br/> Train accuracy: 0.098 Test accuracy: 0.098.\n",
        "\n",
        "What we notice is a marked degradation of model's performance already starting from point 2, meaning we have to focus on smaller degrees of separation, possibly starting from the one of point 1 and increasing the separation at a slower pace (i.e. in couples, in triples etc..). In any case, the performance observed at point 1 is coherent with our expectation of a result below the baseline case, but well above of a ZeroR classifier (about 10% accuracy).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GugnvHXWdWsj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}